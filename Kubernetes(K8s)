 Kubernetes /K8s
is an open source platform designed to automate the deployment,scaling and management of containerized application/containers.
Container Orchestration /container management tool- Kubernetes manages clusters of containers,ensuring they run efficiently across multiple machine.
Features of K8s
- Container orchestration 
- automated scaling
- Self -Healing
- service Discovery & Load balancing
- Storage Orchestration: Kubernetes allows you to automatically mount the storage system of your choice, whether from local storage, cloud providers, or network storage systems.
- Automated Rollouts & Rollbacks: Kubernetes can manage the deployment of new versions of applications without downtime, and roll back to previous versions if something goes wrong.

Architecture of K8s
1)Kubernetes only manage pods not container
2)Worker node/minion
i)Kubelet
- kubelet is the agent running on node
- kubelet communicate the controller manager through API server & send all information to master .
- Observe and manage the pods(how many container should there be in a pod)
- kubelet ensures that the desired state of the containers as defined by master kubelet sees and control all these things
- 

ii) Kube-Proxy
- All networking should be done by kube-proxy
- Assigning ip adress to to pod

A Kubernetes cluster is a group of nodes that run containerized applications and are managed by the Kubernetes control plane
Architecture of kubernetes 
in this architecture kubernetes has two main plane one is control plane and another is worker plane
1) the control plane is responsible for managing the kubernetes cluster
2) it make decision about the cluster,such as scheduling and monitoring the cluster state.

the main component of the control plane is 
- API Server 
- kube scheduler
- controller manager
- etcd
API server
The API server is the front end of the kubernetes control plane
it is basically resposible for communication between control plane and worker plane
and also updates the cluster state in etcd.

kube schedule
the scheduler assign the pods to nodes based on resources availability
it handle pod creation and management

controller manager 
- it is resposible for running controller processess.
controller are resposible for maintaing the desired state of pods

etcd
it store all metadata of cluster in key value format
like configuration and state information

Worker plane
the worker plane consist of worker node that run containerized application
each worker node has essential component that communicate with the control plane

Kubelet
kubelet is the agent running on each node that ensure container are running in a pod.
it communicate with the control plane and receive instruction about which pods to run on the node.

kube proxy 
kube  proxy maintain network rules on nodes ,assigning ip adress and configuring load balancer.
allowing communication between pods and services within the cluster

Container runtime engine
this is the software resposible for running the container
and manage container image on node 

Pods 
pods are the smallest deployable units
the group of one or more conatainer with shared storage and network resources and specification how to run the containers



same version of cluster and  ectl and kubectl

1st install kubctl
eksctl


deployment used for stateless application
statefullset are used for stateful application
  by defualt objects communicate services through headless services

1. Deployment
Purpose: To manage stateless applications.
How It Works: A Deployment ensures that a specified number of pod replicas are running at all times. If a pod crashes or is deleted, the Deployment controller will automatically create a new pod to replace it.
Use Case: Ideal for scalable, stateless applications like web servers, where the state doesn't need to be preserved across restarts.

2. StatefulSet
Purpose: To manage stateful applications.
How It Works: Unlike Deployments, StatefulSets ensure that each pod has a unique, stable identity and persistent storage. Pods in a StatefulSet are created and destroyed in a specific order, and each pod gets a stable network identity and storage that persists across rescheduling.
Use Case: Ideal for applications that require stable, persistent storage and network identities, like databases (e.g., MySQL, MongoDB) or distributed systems.

3. DaemonSet
Purpose: To ensure that a copy of a pod runs on all (or specific) nodes in the cluster.
How It Works: A DaemonSet automatically deploys a pod on every node in the cluster (or a subset of nodes if specified). If new nodes are added to the cluster, the DaemonSet ensures that the pod is also deployed on the new nodes.
Use Case: Ideal for background system services like logging agents, monitoring daemons, or network plugins that need to run on every node.

Summary
Deployment: Use for stateless applications where you need to scale and manage pods easily.

StatefulSet: Use for stateful applications where each pod needs a unique identity and stable storage.

DaemonSet: Use when you need to run a specific pod on every node in the cluster



In Kubernetes, exposing a pod means making it available to the cluster through a service:

Service
A service groups a set of pod endpoints into a single resource and defines a policy for accessing them.

ClusterIP
The default service type that exposes the service on an internal IP address, making it only accessible from within the cluster.

NodePort
Exposes the service on the same port of each selected node in the cluster, making it accessible from outside the cluster

n Kubernetes, the term "expose" refers to making a service or an application accessible to the network. This can mean exposing the service internally within the cluster or externally to the outside world. When you expose a Kubernetes service, you define how the service will be accessed, whether it's from within the cluster, from other services, or from external users.

Here are the common ways to expose a service in Kubernetes:

ClusterIP: This is the default type. It exposes the service on an internal IP within the cluster. This means the service is only accessible from within the cluster.

NodePort: This type exposes the service on a static port on each node’s IP. The service becomes accessible from outside the cluster using the <NodeIP>:<NodePort> combination.

LoadBalancer: This type exposes the service externally using a cloud provider’s load balancer. It automatically provisions a load balancer for the service and directs traffic to the service through it.

ExternalName: This type maps the service to the contents of an external DNS name, returning a CNAME record with the name.


    kubectl expose deployment/my-nginx

